{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd874c62-8f76-4f9c-9fb8-5adb59290cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff92119-690f-4a60-bcbe-b7c8842988e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_csv_path = './archive/sign_mnist_train.csv'\n",
    "train_data = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Load the testing dataset\n",
    "test_csv_path = './archive/sign_mnist_test.csv'\n",
    "test_data = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a75e225-6a12-4877-931b-ac4680d952ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique training classes: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Unique testing classes: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Training Accuracy: 76.39%\n",
      "Testing Accuracy: 63.43%\n",
      "Confusion Matrix:\n",
      "[[323   0   0   0   0   0   0   0   0   0   0   0   3   4   0   0   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  0 349   0   0   0   0   0   0   0  75   0   0   0   0   0   0   0   0\n",
      "    0   0   0   8   0   0]\n",
      " [  0   0 264   0   0  16   0   0   0   0   5   0   0  19   0   0   0   0\n",
      "    0   0   0   0   6   0]\n",
      " [  0   0   0 153   0   0   0   0   0  15   0   0  14   0   0   0   0   5\n",
      "    0   0   6   0  52   0]\n",
      " [  0   0   0   0 435   0   0   0   0   0   0   0   0   0   0   0   0  63\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0  20   0   0 201   0   0   0   0   1   0   0   5   0   0   0   0\n",
      "    0   0   0  20   0   0]\n",
      " [  0   0   0  20   0   0 203  18   0   0   0   0  21  14   0  19   0   0\n",
      "   52   0   0   0   1   0]\n",
      " [  0   0   0   0  16   0  45 348   0   0   0   0   0   0   0   0   0   0\n",
      "   22   0   0   0   5   0]\n",
      " [  3   0   0   0   0   0   0   0 190   0   0   0  21   0   0  12   0  21\n",
      "    0   0   0   0   0  41]\n",
      " [  0   0   0   9   0  21   0   0  24 159   0   0   0   0   0   0  87   3\n",
      "    0   0   0   8   0  20]\n",
      " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [ 24   0   0   0  47   0   0   0   0   0   0 135  45   0   0  39   0 104\n",
      "    0   0   0   0   0   0]\n",
      " [ 42   0   0   4  14   0   0   0   0   0   0  15 139  10   0  33   0   2\n",
      "   32   0   0   0   0   0]\n",
      " [  0   0  17   0  21  21   8   0   0   0   0   0   0 138   0  20   0   0\n",
      "    5   4   0   0  12   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 324  22   0   0\n",
      "    1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   0   0   0   0  21   0   0   0 140   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0  41  62\n",
      "    0  20   0   0   0   0]\n",
      " [  0   0   0   3  22   0   0   0  40   0   0  57  27   0   0   3   0  43\n",
      "    0  18   0  12   0  21]\n",
      " [  0   0   1   0   0   0   0   0  21   0  40   0   0   0  21   0   0   0\n",
      "  104  20   0   0  41   0]\n",
      " [  0  17   0  39   0   3   0   0   0  41   0   0   0   0   0   0  56   0\n",
      "    0  80  30   0   0   0]\n",
      " [  0  11   0   3   0  35   0   0   0  16   0   0   0   0  19   0  32   0\n",
      "    0  50 131  32   0  17]\n",
      " [  0  20   0   0   0   3   0   0   0  20   0   0   0   0   0   0  22   0\n",
      "    0  17   1 123   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   8  24\n",
      "   20   0   0  48 166   0]\n",
      " [  0   0   0  17   0   0   0   0  17   0   9   0   0   0   0   0  63   9\n",
      "   42   0   2  22   0 151]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       331\n",
      "           1       0.88      0.81      0.84       432\n",
      "           2       0.87      0.85      0.86       310\n",
      "           3       0.62      0.62      0.62       245\n",
      "           4       0.78      0.87      0.83       498\n",
      "           5       0.66      0.81      0.73       247\n",
      "           6       0.79      0.58      0.67       348\n",
      "           7       0.95      0.80      0.87       436\n",
      "           8       0.65      0.66      0.66       288\n",
      "          10       0.49      0.48      0.48       331\n",
      "          11       0.73      1.00      0.85       209\n",
      "          12       0.59      0.34      0.43       394\n",
      "          13       0.51      0.48      0.50       291\n",
      "          14       0.73      0.56      0.63       246\n",
      "          15       0.89      0.93      0.91       347\n",
      "          16       0.49      0.85      0.62       164\n",
      "          17       0.13      0.28      0.18       144\n",
      "          18       0.13      0.17      0.15       246\n",
      "          19       0.37      0.42      0.40       248\n",
      "          20       0.38      0.30      0.34       266\n",
      "          21       0.77      0.38      0.51       346\n",
      "          22       0.45      0.60      0.51       206\n",
      "          23       0.59      0.62      0.60       267\n",
      "          24       0.60      0.45      0.52       332\n",
      "\n",
      "    accuracy                           0.63      7172\n",
      "   macro avg       0.62      0.62      0.61      7172\n",
      "weighted avg       0.66      0.63      0.64      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CustomLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000, num_classes=None):\n",
    "        \"\"\"\n",
    "        Initialize the Logistic Regression model\n",
    "        \n",
    "        Parameters:\n",
    "        - learning_rate: step size for gradient descent\n",
    "        - num_iterations: number of training iterations\n",
    "        - num_classes: number of unique classes in the dataset\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_classes = num_classes\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.class_mapping = None  # To handle zero-based indexing\n",
    "\n",
    "    def _softmax(self, z):\n",
    "        \"\"\"\n",
    "        Softmax activation function for multiclass classification\n",
    "        Prevents numerical instability by subtracting max value\n",
    "        \n",
    "        Parameters:\n",
    "        - z: input array of logits\n",
    "        \n",
    "        Returns:\n",
    "        - Softmax probabilities\n",
    "        \"\"\"\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def _one_hot_encode(self, y):\n",
    "        \"\"\"\n",
    "        Convert labels to one-hot encoded format\n",
    "        \n",
    "        Parameters:\n",
    "        - y: original labels\n",
    "        \n",
    "        Returns:\n",
    "        - One-hot encoded labels\n",
    "        \"\"\"\n",
    "        # Remap labels to zero-based index if needed\n",
    "        if self.class_mapping is None:\n",
    "            unique_classes = np.unique(y)\n",
    "            self.class_mapping = {orig: idx for idx, orig in enumerate(unique_classes)}\n",
    "            self.reverse_mapping = {idx: orig for orig, idx in self.class_mapping.items()}\n",
    "        \n",
    "        # Map original labels to zero-based index\n",
    "        y_mapped = np.array([self.class_mapping[label] for label in y])\n",
    "        \n",
    "        # Create one-hot encoding\n",
    "        one_hot = np.zeros((y.shape[0], self.num_classes))\n",
    "        one_hot[np.arange(y.shape[0]), y_mapped] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the logistic regression model\n",
    "        \n",
    "        Parameters:\n",
    "        - X: input features (num_samples, num_features)\n",
    "        - y: target labels\n",
    "        \"\"\"\n",
    "        # Determine number of classes if not specified\n",
    "        unique_classes = np.unique(y)\n",
    "        self.num_classes = len(unique_classes)\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        num_features = X.shape[1]\n",
    "        self.weights = np.zeros((num_features, self.num_classes))\n",
    "        self.bias = np.zeros((1, self.num_classes))\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        Y_one_hot = self._one_hot_encode(y)\n",
    "        \n",
    "        # Gradient descent\n",
    "        for _ in range(self.num_iterations):\n",
    "            # Forward pass\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self._softmax(linear_model)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1/X.shape[0]) * np.dot(X.T, (y_predicted - Y_one_hot))\n",
    "            db = (1/X.shape[0]) * np.sum(y_predicted - Y_one_hot, axis=0, keepdims=True)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on input data\n",
    "        \n",
    "        Parameters:\n",
    "        - X: input features\n",
    "        \n",
    "        Returns:\n",
    "        - Predicted class labels (original class labels)\n",
    "        \"\"\"\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._softmax(linear_model)\n",
    "        \n",
    "        # Get indices of max probabilities\n",
    "        predicted_indices = np.argmax(y_predicted, axis=1)\n",
    "        \n",
    "        # Map back to original class labels\n",
    "        return np.array([self.reverse_mapping[idx] for idx in predicted_indices])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities\n",
    "        \n",
    "        Parameters:\n",
    "        - X: input features\n",
    "        \n",
    "        Returns:\n",
    "        - Predicted class probabilities\n",
    "        \"\"\"\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        return self._softmax(linear_model)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute model accuracy\n",
    "        \n",
    "        Parameters:\n",
    "        - X: input features\n",
    "        - y: true labels\n",
    "        \n",
    "        Returns:\n",
    "        - Accuracy score\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "def preprocess_sign_mnist(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Preprocess Sign MNIST dataset\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: Training dataframe\n",
    "    - test_data: Testing dataframe\n",
    "    \n",
    "    Returns:\n",
    "    - Preprocessed X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Separate features and labels\n",
    "    X_train = train_data.drop('label', axis=1).values\n",
    "    y_train = train_data['label'].values\n",
    "    \n",
    "    X_test = test_data.drop('label', axis=1).values\n",
    "    y_test = test_data['label'].values\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    print(\"Unique training classes:\", np.unique(y_train))\n",
    "    print(\"Unique testing classes:\", np.unique(y_test))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train custom Logistic Regression on Sign MNIST\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - X_test: Testing features\n",
    "    - y_train: Training labels\n",
    "    - y_test: Testing labels\n",
    "    \n",
    "    Returns:\n",
    "    - Trained model\n",
    "    - Training and test accuracies\n",
    "    \"\"\"\n",
    "    # Create and train the model\n",
    "    clf = CustomLogisticRegression(\n",
    "        learning_rate=0.1,  # You can tune this\n",
    "        num_iterations=1000,  # You can increase for better convergence\n",
    "        num_classes=len(np.unique(y_train))\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute accuracies\n",
    "    train_accuracy = clf.accuracy(X_train, y_train)\n",
    "    test_accuracy = clf.accuracy(X_test, y_test)\n",
    "    \n",
    "    return clf, train_accuracy, test_accuracy\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Load the training dataset\n",
    "    train_csv_path = './archive/sign_mnist_train.csv'\n",
    "    train_data = pd.read_csv(train_csv_path)\n",
    "    \n",
    "    # Load the testing dataset\n",
    "    test_csv_path = './archive/sign_mnist_test.csv'\n",
    "    test_data = pd.read_csv(test_csv_path)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X_train, X_test, y_train, y_test = preprocess_sign_mnist(train_data, test_data)\n",
    "    \n",
    "    # Train the model\n",
    "    model, train_acc, test_acc = train_logistic_regression(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Training Accuracy: {train_acc * 100:.2f}%\")\n",
    "    print(f\"Testing Accuracy: {test_acc * 100:.2f}%\")\n",
    "    \n",
    "    return model, X_test, y_test\n",
    "\n",
    "# Optional: Confusion Matrix and Classification Report\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Generate detailed model evaluation\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained logistic regression model\n",
    "    - X_test: Test features\n",
    "    - y_test: Test labels\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    model, X_test, y_test = main()\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e66ec64-5f68-4598-854d-c4e6bac43d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sign_mnist(train_data, test_data):\n",
    "    # Separate features and labels\n",
    "    X_train = train_data.drop('label', axis=1).values\n",
    "    y_train = train_data['label'].values\n",
    "    \n",
    "    X_test = test_data.drop('label', axis=1).values\n",
    "    y_test = test_data['label'].values\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    print(\"Unique training classes:\", np.unique(y_train))\n",
    "    print(\"Unique testing classes:\", np.unique(y_test))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2e8240-c8a8-4a13-828a-14d951e934a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique training classes: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "Unique testing classes: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "X_train, X_test, y_train, y_test = preprocess_sign_mnist(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd075c60-e052-4056-8015-b6705f92e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "clf = CustomLogisticRegression(\n",
    "    learning_rate=0.1,  # You can tune this\n",
    "    num_iterations=1000,  # You can increase for better convergence\n",
    "    num_classes=len(np.unique(y_train))\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485248d3-6425-49d7-9059-a7827bb7f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 76.39%\n",
      "Testing Accuracy: 63.43%\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracies\n",
    "train_accuracy = clf.accuracy(X_train, y_train)\n",
    "test_accuracy = clf.accuracy(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1444857a-3715-45cd-96f8-2f56bbf0b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[323   0   0   0   0   0   0   0   0   0   0   0   3   4   0   0   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  0 349   0   0   0   0   0   0   0  75   0   0   0   0   0   0   0   0\n",
      "    0   0   0   8   0   0]\n",
      " [  0   0 264   0   0  16   0   0   0   0   5   0   0  19   0   0   0   0\n",
      "    0   0   0   0   6   0]\n",
      " [  0   0   0 153   0   0   0   0   0  15   0   0  14   0   0   0   0   5\n",
      "    0   0   6   0  52   0]\n",
      " [  0   0   0   0 435   0   0   0   0   0   0   0   0   0   0   0   0  63\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0  20   0   0 201   0   0   0   0   1   0   0   5   0   0   0   0\n",
      "    0   0   0  20   0   0]\n",
      " [  0   0   0  20   0   0 203  18   0   0   0   0  21  14   0  19   0   0\n",
      "   52   0   0   0   1   0]\n",
      " [  0   0   0   0  16   0  45 348   0   0   0   0   0   0   0   0   0   0\n",
      "   22   0   0   0   5   0]\n",
      " [  3   0   0   0   0   0   0   0 190   0   0   0  21   0   0  12   0  21\n",
      "    0   0   0   0   0  41]\n",
      " [  0   0   0   9   0  21   0   0  24 159   0   0   0   0   0   0  87   3\n",
      "    0   0   0   8   0  20]\n",
      " [  0   0   0   0   0   0   0   0   0   0 209   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [ 24   0   0   0  47   0   0   0   0   0   0 135  45   0   0  39   0 104\n",
      "    0   0   0   0   0   0]\n",
      " [ 42   0   0   4  14   0   0   0   0   0   0  15 139  10   0  33   0   2\n",
      "   32   0   0   0   0   0]\n",
      " [  0   0  17   0  21  21   8   0   0   0   0   0   0 138   0  20   0   0\n",
      "    5   4   0   0  12   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 324  22   0   0\n",
      "    1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   0   0   0   0  21   0   0   0 140   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  21   0   0   0   0   0  41  62\n",
      "    0  20   0   0   0   0]\n",
      " [  0   0   0   3  22   0   0   0  40   0   0  57  27   0   0   3   0  43\n",
      "    0  18   0  12   0  21]\n",
      " [  0   0   1   0   0   0   0   0  21   0  40   0   0   0  21   0   0   0\n",
      "  104  20   0   0  41   0]\n",
      " [  0  17   0  39   0   3   0   0   0  41   0   0   0   0   0   0  56   0\n",
      "    0  80  30   0   0   0]\n",
      " [  0  11   0   3   0  35   0   0   0  16   0   0   0   0  19   0  32   0\n",
      "    0  50 131  32   0  17]\n",
      " [  0  20   0   0   0   3   0   0   0  20   0   0   0   0   0   0  22   0\n",
      "    0  17   1 123   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   8  24\n",
      "   20   0   0  48 166   0]\n",
      " [  0   0   0  17   0   0   0   0  17   0   9   0   0   0   0   0  63   9\n",
      "   42   0   2  22   0 151]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       331\n",
      "           1       0.88      0.81      0.84       432\n",
      "           2       0.87      0.85      0.86       310\n",
      "           3       0.62      0.62      0.62       245\n",
      "           4       0.78      0.87      0.83       498\n",
      "           5       0.66      0.81      0.73       247\n",
      "           6       0.79      0.58      0.67       348\n",
      "           7       0.95      0.80      0.87       436\n",
      "           8       0.65      0.66      0.66       288\n",
      "          10       0.49      0.48      0.48       331\n",
      "          11       0.73      1.00      0.85       209\n",
      "          12       0.59      0.34      0.43       394\n",
      "          13       0.51      0.48      0.50       291\n",
      "          14       0.73      0.56      0.63       246\n",
      "          15       0.89      0.93      0.91       347\n",
      "          16       0.49      0.85      0.62       164\n",
      "          17       0.13      0.28      0.18       144\n",
      "          18       0.13      0.17      0.15       246\n",
      "          19       0.37      0.42      0.40       248\n",
      "          20       0.38      0.30      0.34       266\n",
      "          21       0.77      0.38      0.51       346\n",
      "          22       0.45      0.60      0.51       206\n",
      "          23       0.59      0.62      0.60       267\n",
      "          24       0.60      0.45      0.52       332\n",
      "\n",
      "    accuracy                           0.63      7172\n",
      "   macro avg       0.62      0.62      0.61      7172\n",
      "weighted avg       0.66      0.63      0.64      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Import sklearn metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53ce136-6cdb-420e-9565-85470596e73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABb4AAAExCAYAAACzsrRmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWXUlEQVR4nO3dZ5xW1bn//+ueXmEYZmCoA4JUBYJdBEHsolFRg0YBE0sitpPEFjUaYxJzyPFoYmw/jSa2Y4zhRBNL1GANCWpQemeQNp3pTLvv/X/gnzmOoOs7sKZtP+/XKw8yfrmude+y9tprhiESBEFgAAAAAAAAAACERFxnDwAAAAAAAAAAAJ/Y+AYAAAAAAAAAhAob3wAAAAAAAACAUGHjGwAAAAAAAAAQKmx8AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAgVNr4BAAAAAAAAAKHCxjcAAAAAAAAAIFTY+O7mhgwZYnPnzu3sYQD4imHuAdDdMG8B6MqYowB0FcxHCBM2vvfD448/bpFIpOV/KSkpNmLECLvyyiutqKios4cnicVi9p//+Z82dOhQS0lJsXHjxtkzzzyzT7WmTp3a6nh80f9uv/12vx/Co1WrVtnJJ59sGRkZlp2dbRdddJGVlJR09rCAVsIw9/z0pz+1M844w/r27eucF15//XWbNm2a5eTkWFZWlh1++OH2xBNPtLlnQUGBNEdFIhErKCjY9w/Xjh544AE799xzbfDgwRaJRL50Qfrhhx/ajBkzLC8vzzIyMmzcuHH2q1/9yqLRaMcNGPj/dfd568vmj//5n/9pc73uvmZavHixXXHFFXbIIYdYYmKiRSIR6c+9++67LZ+ttLS0nUcJ6Lr7HLV9+3a78MILbeTIkZaZmdmyXvrd735nQRC0ud7cuXOlOaqrboytWbPG/uM//sOOPvpoS0lJca7tXnjhBZs4caKlpKTY4MGD7bbbbrPm5uaOGzDwGd19Plq9erVdf/31NmHCBMvMzLR+/frZaaedZh988MEe2bbeqy7qu96bb7657x+wnZSVldn8+fNtypQplpuba1lZWXbkkUfas88+u0e2pqbGbrvtNjv55JMtOzvbIpGIPf744x0/6G4iobMHEAZ33HGHDR061Orr6+3dd9+1Bx54wF566SVbvny5paWldfbwvtTNN99sd911l1166aV22GGH2Z///Ge74IILLBKJ2KxZs9pc65JLLmn5/++//7796le/sh/+8Ic2evTolq+PGzfO2/h92rp1q02ZMsV69uxpP/vZz6ympsZ++ctf2rJly2zx4sWWlJTU2UMEWunOc88tt9xieXl59rWvfc1effXVL8y98MILduaZZ9pRRx1lt99+u0UiEfvDH/5gs2fPttLSUvuP//gPuWdubu4eG+b/9V//ZVu3brX//u//3iPbFf3iF7+w6upqO/zww23Hjh1fmPvwww/t6KOPtgMPPNBuuOEGS0tLs5dfftmuueYa27Bhg917770dOGrg/3TnecvM7Pzzz7dTTz211deOOuqoNtfp7muml156yR555BEbN26cHXDAAbZ27Vrnn4nFYnbVVVdZenq61dbWdsAogbbrrnNUaWmpbd261c455xwbPHiwNTU12WuvvWZz5861NWvW2M9+9rM21bv88svt+OOPb/n/mzZtsh/96Ed22WWX2eTJk1u+PmzYMG+fwadFixbZr371KxszZoyNHj3aPvrooy/Mvvzyy3bmmWfa1KlT7de//rUtW7bM7rzzTisuLrYHHnig4wYNfE53nY8eeeQRe/TRR23mzJl2xRVXWGVlpT300EN25JFH2iuvvNJqbmnLvar4/Lve73//e3vttdf2+Ppn11pdxaJFi+zmm2+2U0891W655RZLSEiw559/3mbNmmUrV660H//4xy3Z0tJSu+OOO2zw4ME2fvz4LrmR36UE2GePPfZYYGbB+++/3+rr3/ve9wIzC55++ukv/LM1NTVexpCfnx/MmTNnn/7s1q1bg8TExGDevHktX4vFYsHkyZODgQMHBs3Nzfs1tueeey4ws2DhwoVfmvN1LPbXd7/73SA1NTXYvHlzy9dee+21wMyChx56qBNHBrTW3eeeIAiCTZs2BUEQBCUlJYGZBbfddttecyeccELQv3//oL6+vuVrTU1NwbBhw4Jx48btc//dTjvttCA/P/9LM7FYLKirq9vvXj4UFBQEsVgsCIIgSE9P/8JzcOmllwZJSUlBWVlZq69PmTIl6NGjR3sPE9hDd5+3Nm3aFJhZMH/+fC9j+bzutmYqLCxsmRfnzZsXKK8UDzzwQNC7d+/gmmuuCcwsKCkpae9hArLuPkd9kRkzZgTp6en7/V73/vvvB2YWPPbYY1+a6ypzVFlZWVBVVRUEQRDMnz8/MLOWtefnjRkzJhg/fnzQ1NTU8rWbb745iEQiwapVqzpiuEAr3X0++uCDD4Lq6upWXystLQ1yc3ODSZMmtfp6W+7VfaGuUWpra7313FcbN24MCgoKWn0tFosFxx13XJCcnNzq3NbX1wc7duwIgkCfn7/K+FUn7eC4444zs0+/M2726V8Vy8jIsA0bNtipp55qmZmZ9s1vftPMPv3pl3vuucfGjh1rKSkp1rdvX7v88stt586drWoGQWB33nmnDRw40NLS0mzatGm2YsWKvfbfsGGDbdiwwTnOP//5z9bU1GRXXHFFy9cikYh997vfta1bt9qiRYv26fN/md0/sbly5Uq74IILrFevXnbMMceY2ad/7Xfq1Kl7/Jm5c+fakCFDWn1NPW6VlZW2evVqq6ysdI7t+eeftxkzZtjgwYNbvnb88cfbiBEj7A9/+EPbPyzQwbrL3GNme9zTX6Sqqsp69eplycnJLV9LSEiwnJwcS01NlWq01ZAhQ2zGjBn26quv2qGHHmqpqan20EMPtfyqg739NbK9/UqCbdu22be+9S3r27evJScn29ixY+23v/3tHn/2k08+sdWrV0tjy8/Pl36lQFVVlaWkpFhWVlarr/fr16/djhuwL7rTvLVbbW2tNTY2tvWjtllXXjP17du3TXNJeXm53XLLLXbHHXfsMS8BXVl3nKM+a8iQIVZXV9cuc9buX8fw1ltv2RVXXGF9+vSxgQMHmtne5yKz/5vXPu/JJ5+0Qw45xFJTUy07O9tmzZplW7ZsaZWpq6uz1atXS78mKTs72zIzM525lStX2sqVK+2yyy6zhIT/+8vwV1xxhQVBYH/84x+dNYCO0l3mo0MOOcQyMjJafa137942efJkW7VqVauvq/eqT1OnTrWDDjrIPvzwQ5syZYqlpaXZD3/4QzPb+zud2d5/53lFRYVde+21NmjQIEtOTrbhw4fbL37xC4vFYq1yO3bssNWrV1tTU9OXjmvo0KGWn5/f6muRSMTOPPNMa2hosI0bN7Z8PTk52fLy8trwqb/a2PhuB7sng969e7d8rbm52U466STr06eP/fKXv7SZM2ea2ad/jey6666zSZMm2b333msXX3yxPfXUU3bSSSe1ujF+9KMf2a233mrjx4+3+fPn2wEHHGAnnnjiXv+q6PTp02369OnOcS5ZssTS09P3+Gsehx9+eMt/by/nnnuu1dXV2c9+9jO79NJL2/zn1eO2YMECGz16tC1YsOBL623bts2Ki4vt0EMP3eO/HX744e16LABfusvc0xZTp061FStW2K233mrr16+3DRs22E9+8hP74IMP7Prrr/fa67PWrFlj559/vp1wwgl277332oQJE9r054uKiuzII4+0119/3a688kq79957bfjw4fbtb3/b7rnnnlbZ2bNne//rdlOnTrWqqiq7/PLLbdWqVbZ582Z78MEH7U9/+pPddNNNXnsB+6O7zVs//vGPLSMjw1JSUuywww6zv/3tb/v60WVdbc20L2699VbLy8uzyy+/3HttoD11tzlq165dVlpaagUFBfa73/3OHnvsMTvqqKPa9ZveV1xxha1cudJ+9KMf2Y033tjmP//Tn/7UZs+ebQceeKDdfffddu2119obb7xhU6ZMsYqKipbc4sWLbfTo0Xbfffd5G/vud7zPvwP279/fBg4cyDsgupTuNh99XmFhoeXk5Ozzn/eprKzMTjnlFJswYYLdc889Nm3atDb9+bq6Ojv22GPtySeftNmzZ9uvfvUrmzRpkt100032ve99r1X2pptustGjR9u2bdv2aayFhYVmZl3m2HVH/I5vDyorK620tNTq6+vtvffeszvuuMNSU1NtxowZLZmGhgY799xz7ec//3nL195991175JFH7KmnnrILLrig5evTpk2zk08+2Z577jm74IILrKSkxP7zP//TTjvtNHvxxRdbvkt+8803t/n3tX3Wjh07Wv5huc/q16+fmX36j6S0l/Hjx9vTTz+9T39WPW5tsft35e7+7J/Vr18/Ky8vt4aGhlY/dQp0tu4697TFrbfeaps2bbKf/vSnduedd5qZWVpamj3//PP29a9/vd36rl+/3l555RU76aSTWr7Wln9o5eabb7ZoNGrLli1rWZx+5zvfsfPPP99uv/12u/zyy9v1JfTSSy+1FStW2EMPPWSPPPKImZnFx8fbfffdZ9/5znfarS/g0l3nrbi4ODvxxBPtrLPOsgEDBtjGjRvt7rvvtlNOOcVeeOEFO+200/a5tktXWzO11dKlS+2hhx6yl156yeLj49u1F7C/uusctdu9997b6hvc06dPt8cee2y/636Z7Oxse+ONN/bp/t68ebPddtttduedd7b8xKWZ2dlnn21f+9rX7P7772/1dd9c74Dt+T4MuHT3+eiz3nnnHVu0aJHdcsstXuvuq8LCQnvwwQf3+Rvyd999t23YsMGWLFliBx54oJl9+s2G/v372/z58+373/++DRo0aL/HWV5ebo888ohNnjx5r/MUNPzEtwfHH3+85ebm2qBBg2zWrFmWkZFhCxYssAEDBrTKffe73231/5977jnr2bOnnXDCCVZaWtryv91/NWThwoVmZvb6669bY2OjXXXVVa02qa+99tq9jqegoEDaoNm1a9deN3JTUlJa/nt72Z+NF/W4mX3613+CIHD+i+O7P2tnHQ9gX3TXuactkpOTbcSIEXbOOefYM888Y08++aQdeuihduGFF9o///lPr70+a+jQoa02vdsiCAJ7/vnn7fTTT7cgCFod45NOOskqKyvt3//+d0v+zTfftCAIfA3dzD7d5B42bJiddNJJ9rvf/c6effZZO/300+2qq66y//3f//XaC2iL7jpvDR482F599VX7zne+Y6effrpdc801tmTJEsvNzbXvf//7bTsIbdTV1kxtdfXVV9spp5xiJ554ote6QHvornPUbueff7699tpr9vTTT7dseLX3O8yll166z9/U+tOf/mSxWMzOO++8VsctLy/PDjzwwFZz1NSpUy0Igr3+GoJ95XoH5P0Pnam7z0e7FRcX2wUXXGBDhw5t17+x2xbJycl28cUX7/Off+6552zy5MnWq1evVsf4+OOPt2g0am+//XZL9vHHH7cgCORf9blbLBazb37zm1ZRUWG//vWv93ms4Ce+vfjNb35jI0aMsISEBOvbt6+NHDnS4uJaf08hISGh5Xee7bZu3TqrrKy0Pn367LVucXGxmX36nXAza/lO0m65ubnWq1evfR53amqqNTQ07PH1+vr6lv/eXoYOHbrPf1Y9bm2x+7N21vEA9kV3nXva4sorr7R//vOf9u9//7vls5133nk2duxYu+aaa+xf//pXu/TdnzmqpKTEKioq7OGHH7aHH354r5l9mafa4q677rJ7773X1q1b1/I79s477zybNm2azZs3z2bMmNHqd1kCHSVM81Z2drZdfPHFdtddd9nWrVv3GLMvXW3N1BbPPvus/eMf/7Dly5e3ax/Al+4+R+Xn57f8jtjzzz/fLrvsMjv++ONtzZo17fYus79zVBAEexyP3RITE/e5tsL1Dsj7HzpTd5+PzD79d1FmzJhh1dXV9u677+7xu787y4ABAywpKWmf//y6dets6dKllpubu9f/7mN9ddVVV9krr7xiv//97238+PH7Xe+rjLdeDw4//PC9/m7oz0pOTt5jkorFYtanTx976qmn9vpnvugm8qVfv362cOFCC4Kg1Xf4dv+Vr/79+7db770tIiKRyF5/6jEajbb6/+1x3Hb/tZHdn/2zduzYYdnZ2fyaE3Q53XXuUTU2Ntqjjz5q119/favPkJiYaKeccordd9991tjYuF+Lli/yRXPU3uxtjjIzu/DCC23OnDl7/TPjxo3bzxF+ufvvv9+OO+64PRaXZ5xxhn3ve9+zgoICGz58eLuOAdibsM1bu/8aa3l5ebttfHe1NVNbXHfddXbuuedaUlJSy0+J7f6dvVu2bLHGxsZ2XW8CbRW2Oeqcc86x//f//p+9/fbb+/w32Vz2d80UiUTs5Zdf3utPjbf3Jtln3wE//2sJduzY0fJvXwGdobvPR42NjXb22Wfb0qVL7dVXX7WDDjqoQ/oq2vpNrb3NXSeccMIX/gT7iBEj9nlsZp/+mzL333+/3XXXXXbRRRftVy2w8d2phg0bZq+//rpNmjTpS2+83d+1X7dunR1wwAEtXy8pKdnjX+VtiwkTJtgjjzxiq1atsjFjxrR8ffdPULb1H3PbX7169Wr1L9Xutvs7kbupx60tBgwYYLm5ufbBBx/s8d8WL17c4ccCaE+dPfeoysrKrLm5eY+FhplZU1OTxWKxvf639rL7Jx8++w8tme05R+Xm5lpmZqZFo1E7/vjjO2p4rRQVFX3hcTP79B/CAbqTrjpv7V63dPSmVmeumdpiy5Yt9vTTT+/1d5RPnDjRxo8fbx999FGHjwvwravOUbt/VUdlZaX32l+mV69ee6yXzPY+RwVBYEOHDt3vjaJ9sfsd74MPPmi1yb19+3bbunWrXXbZZR0+JmB/dYX5KBaL2ezZs+2NN96wP/zhD3bsscfuV72Osre5q7GxcY8fkBw2bJjV1NS0y7veb37zG7v99tvt2muvtRtuuMF7/a8ifsd3JzrvvPMsGo3aT37ykz3+W3Nzc8sNd/zxx1tiYqL9+te/bvXTPffcc89e627YsKHlX/z9Ml//+tctMTHR7r///pavBUFgDz74oA0YMMCOPvrotn2g/TRs2DBbvXq1lZSUtHzt448/tvfee69VTj1uZp8u8lavXi0t9mbOnGl/+ctfbMuWLS1fe+ONN2zt2rV27rnn7sMnArqmzp57VH369LGsrCxbsGCBNTY2tny9pqbGXnzxRRs1alSHbuT06NHDcnJyWv3ONjNrNYeaffr7tWfOnGnPP//8Xv96/2fnODOzTz75xFavXu11rCNGjLDXXnvNysrKWr4WjUbtD3/4g2VmZtqwYcO89gPaW2fPW5+/b83Mtm3bZr/97W9t3LhxHf4PDnX2mkm1YMGCPf73jW98w8zMfv/739t///d/e+sFdKauOEeZmT366KMWiURs4sSJ7g/h0bBhw6yystKWLl3a8rUdO3bYggULWuXOPvtsi4+Ptx//+Md7/C2WIAharWPq6ups9erVVlpa6m2cY8eOtVGjRtnDDz/c6gcGHnjgAYtEInbOOed46wV0lM6ej8w+/TUdzz77rN1///129tlnt/kzdJZhw4bt8a73+fnB7NNjvGjRInv11Vf3qFFRUdHqh4x27Nhhq1evbvkBpC/z7LPP2tVXX23f/OY37e67797HT4HP4ye+O9Gxxx5rl19+uf385z+3jz76yE488URLTEy0devW2XPPPWf33nuvnXPOOZabm2s/+MEP7Oc//7nNmDHDTj31VFuyZIm9/PLLlpOTs0fd6dOnm5k5/+GBgQMH2rXXXmvz58+3pqYmO+yww+x///d/7Z133rGnnnqq1V83e/zxx+3iiy+2xx57zPs/erTbt771Lbv77rvtpJNOsm9/+9tWXFxsDz74oI0dO9aqqqpacupxM/v0hUsd9w9/+EN77rnnbNq0aXbNNddYTU2NzZ8/3w4++OD9+ocPgK6ms+ceM7MnnnjCNm/ebHV1dWZm9vbbb9udd95pZmYXXXSR5efnW3x8vP3gBz+wW265xY488kibPXu2RaNRe/TRR23r1q325JNPtqo5depUe+utt7z/Q5Gfdckll9hdd91ll1xyiR166KH29ttv29q1a/fI3XXXXbZw4UI74ogj7NJLL7UxY8ZYeXm5/fvf/7bXX3/dysvLW7KzZ8+Wx/3iiy/axx9/bGaf/vT20qVLW47bGWec0fIrVG688Ua78MIL7YgjjrDLLrvMUlNT7ZlnnrEPP/zQ7rzzznb/nZmAb509b11//fW2YcMGmz59uvXv398KCgrsoYcestraWrv33ntbZb8Ka6bNmzfbE088YWbW8rflds9F+fn5LX8t98wzz9zjz+7+Ce9TTjllr+cE6I46e4766U9/au+9956dfPLJNnjwYCsvL7fnn3/e3n//fbvqqqta/XqzN99806ZNm2a33Xab138o8rNmzZplN9xwg5111ll29dVXW11dnT3wwAM2YsSIVv/A97Bhw+zOO++0m266yQoKCuzMM8+0zMxM27Rpky1YsMAuu+wy+8EPfmBmn/4tXHXclZWVLf8Y3O5vCN53332WlZVlWVlZduWVV7Zk58+fb2eccYadeOKJNmvWLFu+fLndd999dskll9jo0aM9Hxmg/XX2fHTPPffY/fffb0cddZSlpaXt8c521llnWXp6upm17V6dO3eu/e53v7NNmza1+R+KVF1yySX2ne98x2bOnGknnHCCffzxx/bqq6/ucTyuu+46e+GFF2zGjBk2d+5cO+SQQ6y2ttaWLVtmf/zjH62goKDlz9x0003SuBcvXmyzZ8+23r172/Tp0/f4VTVHH310q5/Mv++++6yiosK2b99uZp++J27dutXMPv3GQ8+ePX0cknAIsM8ee+yxwMyC999//0tzc+bMCdLT07/wvz/88MPBIYccEqSmpgaZmZnBwQcfHFx//fXB9u3bWzLRaDT48Y9/HPTr1y9ITU0Npk6dGixfvjzIz88P5syZ06pefn5+kJ+fL32GaDQa/OxnPwvy8/ODpKSkYOzYscGTTz65R+7Xv/51YGbBK6+8ItUNgiB47rnnAjMLFi5c2PK12267LTCzoKSkZK9/5sknnwwOOOCAICkpKZgwYULw6quvBnPmzNnr51GO2+5z9Nhjj0ljXr58eXDiiScGaWlpQVZWVvDNb34zKCwslD8z0BHCMPcce+yxgZnt9X+fnTOCIAieeuqp4PDDDw+ysrKC1NTU4Igjjgj++Mc/7lHzkEMOCfLy8qT+u5122ml7jDk/Pz847bTT9pqvq6sLvv3tbwc9e/YMMjMzg/POOy8oLi4OzCy47bbbWmWLioqCefPmBYMGDQoSExODvLy8YPr06cHDDz+812OhmDNnzhcet8/Pc6+88kpw7LHHBjk5OUFSUlJw8MEHBw8++KDUB/Ctu89bTz/9dDBlypQgNzc3SEhICHJycoKzzjor+PDDD/fIfhXWTAsXLvzCuejYY4/90j/r+lxAZ+juc9Tf/va3YMaMGUH//v2DxMTEIDMzM5g0aVLw2GOPBbFYrFX2xRdfDMysTWuC999/f4/5wXXM/va3vwUHHXRQkJSUFIwcOTJ48sknW+7/z3v++eeDY445JkhPTw/S09ODUaNGBfPmzQvWrFnTktk973x+vbU3mzZt+sI5am/Hc8GCBcGECROC5OTkYODAgcEtt9wSNDY2OvsA7aG7z0df9r5iZsGmTZtasm25V2fOnBmkpqYGO3fudI5ht3nz5u0x5xx77LHB2LFj95qPRqPBDTfcEOTk5ARpaWnBSSedFKxfv36vx6O6ujq46aabguHDhwdJSUlBTk5OcPTRRwe//OUvW80fu4/HZz/33uw+7+q7Xn5+vnSMEQSRIGjHH41DaJx33nlWUFBgixcv7uyhAMAeqqurLTs72+655x6bN29eZw8HwFcYayYAXdn1119vzzzzjK1fv96Sk5M7ezgAIOnbt6/Nnj3b5s+f39lDQTfDrzqBUxAE9uabb+7xV1QAoKt4++23bcCAAXbppZd29lAAfIWxZgLQ1S1cuNBuvfVWNr0BdBsrVqywXbt28Y89Yp/wE98AAAAAAAAAgFCJ6+wBAAAAAAAAAADgExvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKgkqMG//OUv7mIJWrm4OPd+u5JRe6q1FJFIxEvGzO9xUKjj6khBEEg5ZezKsYrFYlI/JReNRqVaCuU4+DxWKqXnlClTvPXbH0uXLnVm1PvJ533nq19Hj8knn/edWssXn/181mpubu7QfkotZUw++5lp8/C0adP2dzhevP32285Md77P4Z/PdYZyT/lci/jq57uWQjnu6rlRxnXmmWdKtdrbHXfc4cwkJydLteLj450Z9b1RySUmJnoZk5pTx+5rTe6zn3JNqs8in7WgXy/Kcff5PnjOOed4q7U/brzxRmcmKSlJqqXkOnq+U+YxtV9H70f57OezTlNTkzOjvnP42mvy+X6mrn2UNYtyDtV3vY5+B7322mudGZ5EAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACESoIajItz75FHIhGplpKLj4+XavmifD41p9ZSKMfKZ7+OFovFpJyvz6jWCYLAWy31vnCJRqNSThm7OialVleRkCBPZ04+76mOnjN8Usal3sMdyeeYOvpaaG5ulmop17t6HHwdr656HXcViYmJHdrP17PHN5/ziq/nnc9rVxl7ZzxblePgc1zqmkWhjMvnce+q9057U54r6r2ivMep73rK3Olz7Eo/n8fB5xzVFa9dn+9eiq76juPz3VKp1Z3e4XzyuaejzlFKLWVeUfv5nDN8HQefc6JCXWP4PO5NTU3OjM9zo6xr1PWyr+Ou7rcox0rlbR/QSxUAAAAAAAAAALoINr4BAAAAAAAAAKHCxjcAAAAAAAAAIFTY+AYAAAAAAAAAhAob3wAAAAAAAACAUGHjGwAAAAAAAAAQKmx8AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAiVBDUYHx/vzEQiEa1pgrutWkvJKRnl85mZxcX5+16Bz2OqCILASx2fY4rFYt5yyrnxeY1Go1GplvoZXdRrVBmXz+u4O1E/t8/jo9TqzudDuVc6+j5XxmRm1tjY6Mw0NzdLtZSeytjVY1VTU+Oln5k2duU4+DzPYaTO4Qpfax8zbW2gZLrqPOZzzaLwOecnJyc7M+ocpdx3ynlWj6fPOcPXukZdB/u83tW1YleQmJjozKjPVyWn9DPT5k4l43PsPt8bfc7nvuZhn/O5et/56unrfbcr9+yMd/GuwOe7fke/6/m8zxXq51PmMp/vXkot5f0sKytL6vf3v//dmVHv3ylTpjgztbW1Ui2Fcm/63I/y9R5upj3f1ePuax3VNd9SAAAAAAAAAADYR2x8AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAgVNr4BAAAAAAAAAKHCxjcAAAAAAAAAIFTY+AYAAAAAAAAAhAob3wAAAAAAAACAUElQg5FIxEvGzCwIAm+1fPXzWUsdu5Lr6H4JCe5LIhqNSv0USUlJ3mo1Nzc7Mz6vq7g4f983Us5zLBbz1k8du8/j1d6Uz6R+bp/nVrmnfPI5dp/XnEKZD0pLS52ZNWvWSP1GjhzpzOTk5Ei1li5d6sysWrXKmRk4cKDU74gjjnBm6urqpFrl5eXOTEZGhjOTkpIi9auvr5dyCp/Xe3tTxhofHy/VUp7D6rFRe7r4nC/UMfla36n9lM+ojKm6ulrqp+QyMzOlWspnVK4rZa1lpq0f1DVgamqqM1NTU+PMqM/jrnh/dQTlnKmfJzEx0ZlRz4fSU6mljEmt5XM9qWQ6ej2ufj5lTlSPuzLfKddCenq61M/nM0uZM5Sx+9yzUHWnOcrnval87o6+z32uaX3O1T6vEeUzKmuD/v37S/0KCgqcmZUrV0q1pk+fLuV86U7vOJ/na5/Tp+57NAEAAAAAAAAA2As2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACJUENRgEgbtYglYuEol4yag5ZVzq2GOxmLdaycnJzkxTU5MzE41GpX51dXXOTE1NjTPTt29fqZ9yzRQWFkq14uLc36PJy8tzZpTjqfZTKddDc3OzMxMfHy/1U++djq7VFajnVb2Hffbsiv2UWr4yZtr8umXLFmfmrbfekvr99a9/dWbOOussqZYyd27YsMGZ+Z//+R+p37XXXuvMJCUlSbUWLVrkzCif79xzz5X6Kc+QxsZGqVZ3kpiY6Myoc65yT3X0/K0+o3xS1hkdPa5du3Y5M5WVlVKtbdu2OTNpaWlSLeU4KPedOq80NDQ4MytWrJBqTZw40ZmZMGGCM1NRUSH1U6hr7+60jvL5vqRcb+raQJk7lX7qXKCMSxmTWsvnNaL0U+ZNdUzKui0jI0OqpdyfixcvdmZOO+00qV99fb0z052fySrlHHYVyljV4+xzzlDmxY6eo9T51de4lHnFTDuHyh6ZssZQ9e7d21stn3sIyjFV71/1meWi7Fn55msdz098AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAgVNr4BAAAAAAAAAKHCxjcAAAAAAAAAIFTY+AYAAAAAAAAAhAob3wAAAAAAAACAUGHjGwAAAAAAAAAQKglqMBKJeGsaF+feb1f7KbWUTCwW89avqalJqrV+/XpnJjs725kZPXq01G/p0qXOzJtvvunMJCRol803vvENZ6a0tFSq9de//tWZOeGEE5yZU089VepXXFzszGzfvl2qtXXrVmfmmGOOcWZqa2ulfur5CRvl3uyMWr76dfSYzMzq6uqcmY8//tiZUa/J8ePHOzMpKSnOzNChQ6V+H374oTOjzD1mZj/4wQ+cmRUrVjgz6tjvu+8+Z2b69OlSLcWSJUucmfLycqnWXXfd5cw0NjZKtTrjvthX8fHxnT2EfaaMPRqNdsBI2k5Z323btk2qpVyXWVlZzkyfPn2kfkqthoYGqVZRUZEzo9znmZmZUr9BgwY5M+ra+4knnnBmlM933HHHSf2UY6rOUUEQSLmuQHlWq/OYMjcnJiZKtZSePsfus5byPusr47uWr37qPXDAAQc4Mx988IEzs3btWqnfmDFjnJldu3ZJtZTrQbkn1GOl5NTz3NzcLOW6AuXe9PkerNbytRZV6yhzp8+9NIU6JyrXW3p6ujOj3ivKvlxycrJUS31muajHXFlXr1q1Sqq1bNkyZ2bWrFnOjM97oqPfG7rPGyMAAAAAAAAAAAI2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKgkqMG4OPceeSQSkWopObWWr36xWEyqlZKS4qWfmdmuXbucmQULFjgzOTk5Ur+BAwc6M3l5ec7M66+/LvWbNWuWM5OamirVysjIcGaef/55qZYiMzPTmRk0aJBU689//rMzo5ybYcOGSf2qqqqcmYQE7dYPgkDKdQXKZ1LmMZXPWj77NTc3OzPKPGZmVl9f78yUl5c7M5s3b5b6LVu2zJk59dRTnZn09HSpnzJ3FhQUSLWU46DMK+p8rpzD9evXS7Wys7Odmfz8fGfm/fffl/qtXbvWmRkyZIhUq6amRsp1BfHx8d5qdfQaqaOpY/L1jBowYICUa2xsdGbU+VWhXN9NTU1SLWW9NXz4cGdm5cqVUj/lWdS3b1+pVmVlpTPzwQcfODPqdXXQQQc5M8p8bqafn+5CnceUnHo+lPWPkvE5dnVN5vP92Vc/n+tX5VhFo1GpljJ3jh8/3plZunSp1G/MmDHOTFJSklTLF/XcKM8+9fmYmJgo5boC5V1P/Tw+701fc4Z6/pVxddX3VOX8+FxHKeNS3xt9PhsUyvqhsLBQqrVkyRJnZubMmc6MunenrAFV6j6tCz/xDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIlQQ1GB8f78xEIhGplppTKONSBEEg5fLy8pyZWCwm1Tr44IOdmaVLlzozv/3tb6V+V199tTNTW1vrzKSlpUn9EhMTnZmmpiapVmpqqjOzdu1aZ+a9996T+g0ZMsSZOfDAA6VakyZNcmZef/11ZyYpKUnq179/f2dm165dUq24uO7zvbGEBPd05vPzqLU6+hgq14k6ppSUFGdm9OjRzkyPHj2kfsr9uXDhQmdm5MiRUr/169c7M42NjVKtl156yZkZOnSoM6POiRkZGc5MVVWVVGvAgAHOjHLNqM8+5TmjznfKfd9VdNX5tKuOS6Gs3ZR1YkVFhdRvx44dzoxyfav9iouLnZlPPvlEqqUch6997WvOzIQJE6R+0WjUmVHmMTOzNWvWODNZWVnOTENDg9TvmWeecWYuvvhiqZa6Zu4KlPlUfYdTaqnzt69aPtdt6vunUks5pl11nq6pqXFmkpOTpVrKe+Ohhx7qzGzYsEHqt337dmcmPz9fqlVfX+/M+DyHyjWj7m18VSn3sHrOlFo+50RlXD7H7vNYKZR+6l6Gcq+oc5Sv466+Lylrlp07d0q1lP2h7OxsZ6aurk7q52uP1kw/Xi5d8ykKAAAAAAAAAMA+YuMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACESoIajEQiXjKq+Ph4KZeYmOjMNDc3OzPZ2dlSv6qqKmemoaFBqpWcnOzMZGVlOTMvvfSS1G/79u3OTHp6ujOTkZEh9UtKSnJmlPNnZrZlyxZn5qCDDnJmJk2aJPV79913nZmamhqp1gEHHODMNDU1OTN//etfpX5HHXWUM6McKzOz+vp6KYf9Exfn/h6kklHFYjEpV1xc7Mzk5eU5M9u2bZP6DR061Jl56623nJkePXpI/ZScWmv58uXOzMiRI52ZXr16Sf2Uc6jMwWZmtbW1zow63ynUcSkSEuRlTKfzeQ/7XG/5oq7bgiBwZtTPp/RUnmPK+sjMrLGx0ZlJSUlxZqqrq6V+BQUFzkxhYaFUy1c/ZR4z054Ny5Ytk2qtX7/emSkrK3NmRo0aJfVbvXq1M7Nz506p1s033yzlugLlflLvc5/rGmU+UMalPi+UnM+xd/SxUubgzMxMqd/KlSudGfU+v+KKK5wZZV4ZPny41E8Z14gRI6Raynuccl0p58a3aDTa4T33lXJ8lH0fM79r0Y4+b8p84HMvraMpe2QVFRVSLeX6VtZ2Zv6ekeo1qryfqWtAZe2WmprqzKj7nD6p+xYu/MQ3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBUEtRgJBJxZuLitH30+Ph4b7UUQRA4M9nZ2VKtlStXOjN1dXVSrV69ejkz69atc2aSk5Olfk1NTc7Mzp07nZm0tDSpX01NjTNTWFgo1SooKHBmjjzySGcmKSlJ6rdq1SpnZseOHVKtyZMnOzP19fXOjHItmJn95je/cWbuv/9+qZbP+7C9+RxrR3/ujh67eg+vWbPGmVHmldTUVKlfSUmJM6Pcm4MHD5b6DRo0yJmJxWJSrW3btjkz27dvd2aqq6ulfo2Njc6MOnblmklIcC8X1H7l5eXOjDpXq8/brsDnOkrh8/wrY1fWWmqt5uZmqVZRUZEzo6w5x4wZI/WLRqPOTHFxsTNTW1sr9VOOlTr2ESNGODN//etfnZmjjz5a6te/f39nRnnGmJmdfvrpzsx7773nzPzlL3+R+inX35IlS6RaDzzwgDNz2GGHSbXamzIXKPeTWkud75Tnj5JR+/kcu89aCuX8KPOYcjzNzEaNGuXMLF68WKr1wgsvODPz5s1zZoYMGSL1e+edd5wZZV1qZta7d29nRlkvd/T+h++e7U15JqrXrlJLne981eroucAntZ+yNk1JSXFm1GOl3AfKPoxKGZe6xlXGpa4nJ06c6Mwo75bqcVfOs3LfmJklJiZKOZfuM9MBAAAAAAAAACBg4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIRKgs9ikUhEysXFuffb4+PjpVrNzc3OjDKulJQUqV9qaqoz09DQINXasmWLM7Nx40ZnZuDAgVK/+vp6Z6agoMCZUc+zMvaioiKp1q5du5yZIAicmcbGRqlfZmamM3PwwQdLtTIyMpwZ5ZpRj5VyTyjHCl9OmcfUnJKJxWJSv4QE97ReU1Mj1VLu4WXLljkzM2fOlPqtXLnSmamoqHBmtm7dKvWrq6tzZjZv3izVKi0tdWaUOX/FihVSv379+jkzM2bMkGrV1tY6M8p5TktLk/op5ycpKUmqpd6HXYH6mRTKHK6uoxTK/KP2U9YQ6rName+Sk5OdmerqaqlfWVmZM7Nq1SpnZvv27VI/ZY5Sn+fK3KKsfSZNmiT1U673kSNHSrWU6+GII45wZsaNGyf1u/76652Z/v37S7XWrVsn5boC5d7sjHc9X/O8OnYl53MNqBwHn2NXMuq77IQJE5wZZZ42M1u4cKEz89prrzkzY8eOlfop7/TqelJZkzU1NTkz6nWlXg+K7vROmJiY6Myo84pyXSr9zLTz5nNeUT6jz1o+60SjUWemR48ezox6D1RWVjoz6l6acj0o60llX8tMew9X9zBHjBjhzHT0Wl+9RpW9LUX3eWMEAAAAAAAAAEDAxjcAAAAAAAAAIFTY+AYAAAAAAAAAhAob3wAAAAAAAACAUGHjGwAAAAAAAAAQKmx8AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAiVBDUYiUTacxzt2i8vL8+Zqa2tlWpVVFQ4M3V1dVKthoYGZyY7O9uZiY+Pl/pt2bLFmSkrK3NmmpqapH6bN292ZpTjqeaSkpKcmeLiYqnfpEmTnJnU1FSp1vLly50Z5dwsXrxY6nfuuec6Mz179pRqlZaWSrnuIi5O+15fQoI8NXZoLV/9ampqpFoHHHCAM7Nz505npry8XOqnnJ+UlBRnxue8UlVVJdVS5v3Vq1c7M1u3bvXWb/jw4VKt9evXOzM9evTwkjHTng3qvdqd+PxMsVjMWy1lXMqazOfnU9cZSk/lPl+xYoXUb+XKlc7Ma6+95syoaxFlPo9Go1KtiRMnOjM33XSTM6OuOevr66WcL0VFRc7Miy++KNUaPXq0M5OTkyPVamxslHJdgXI/qfe5Mmeo15KvOUpdj/mcy3wdU/W9WHk2ZGRkODPV1dVSP2XuPPTQQ6Vaylrk8ccfd2auvvpqqZ9yDxcUFEi1jjnmGGdGWbep94RyPQRBINVSc12Bcq/4nFfUtVZH3+c+5yhlDaEcU/VZl5mZ6cw0Nzc7M8q7hJm2BlTnKOV6UPb31HtuyZIlzsyQIUOkWunp6c6M+s6r8Hl/+dpLCd+bJQAAAAAAAADgK42NbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQiVBDcbFuffIExK0cvHx8WpbL3JycpyZXbt2SbVqamqcmX/9619SraysLCnnUlJS4qWOmXZuiouLpVppaWnOzJYtW6RaQ4YMcWaOPPJIZ6aqqkrql5ub68wsXbpUqrV+/XpnZtmyZc5MLBaT+p1yyinOTF1dnVQrKSlJynUFPucoX/181lLPv1JLuTfNzA488EBnprCw0EvGzGzgwIHOzLp165yZpqYmqV/fvn2dmaKiIqlWc3OzlHNRr9GNGzc6M6tWrZJqKc/IXr16OTPK8TTTzqF6PH3e092Jz/mno/tFo1FvtRobG52Zd99915l54403pH4rV650Zmpra52ZxMREqZ+SKy8vl2p9/etfd2aUtdaOHTukfsr6QTl/Ztp6+fe//70zo65fx40b58wo59lMm++6CuUdIBKJSLWUOcNnLZ/9lJw6Jyq5IAi8jMlMu++UjHp9P/vss86Mugbs37+/M5Odne3MPProo1K/Pn36ODPqcfD1DuLzWateM8r11534vM99Hhtf85iZ/hkVPXv2dGZWr17tzKj7X2PGjHFmGhoavPVT1iwpKSlSLeX90tfxNDMrLS11ZubMmSPV8vWcUa9Rdd9C4et65ye+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIlQSfxSKRiLdacXHannx8fLyXWs3NzVK/3NxcZ2bw4MFSrTfeeMOZeeutt5yZ6dOnS/1GjRrlpV9KSorUb+DAgc7MWWedJdXq37+/M1NRUSHVUvzrX/9yZvLy8qRamzZtcmb+8Y9/ODPHHXec1E857jt37pRqqfdhV+BzrEqtjj42nXEuysrKnJn6+npnRrkHzMxKS0udmfLycmcmOztb6peRkeHMNDY2SrVisZgzU1lZ6cyo8/mxxx4r5RQDBgxwZpRzox73devWOTPFxcVSrR49eki57kK9z32uaxIS3EtB5fpWxx6NRp0ZZW1npt2fyrW0bds2qZ/yGbOyspwZ5ZibmaWlpTkzTU1NUq1+/fo5M8rxTEpKkvop0tPTpdzmzZudmUWLFjkzQ4YMkfop905tba1Uq7q6Wsp1F+q7ns93QqVWR7+Dqvewr/WkMgebmQ0aNMiZKSoqcma2bNki9Vu7dq0zs2TJEqnWT37yE2dm/Pjxzswf//hHqZ8ydnWO2rp1qzOjvDc2NDRI/Xzyee90BT7vTXUtovZ08bkGVCmfUVm3Kc9pM7OPP/7YmVHeLZWMmfaszszMlGqpPV2UY2BmlpOT48yMHTtWqqWM3ed1pcwr6v2lrnNdus+uFgAAAAAAAAAAAja+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqCSowbi4jt0jD4JAyiUlJTkzytirq6ulfor+/ftLuSOPPNKZqaysdGZKS0ulfn/605+cmS1btjgz6enpUr9hw4Y5M4MHD5ZqffLJJ85MVVWVM1NXVyf1KygocGaUManKy8udmSlTpki1YrGYMxOJRLzV6ip8zlFKrY7u57NWYWGhVEu5xpU5qr6+XupXVFTkzCQkuB9b27dvl/op911NTY1UKy8vz5kZP368MzNr1iypX0ZGhjOjHE8zs82bNzszzc3NXjJm2jEtKSmRavXp00fKdQXKtatS5nC1n1IrPj7emfE5j0WjUSnX0NDgzChjV6/d5ORkKeeifj51zaIYPny4M6OMSzmeZtoxVdeTL7/8sjOjrAGzs7Olfsoza8OGDVKtyZMnS7muQJkL1PWjz1oKn3OUklPH7quW+l6sHIfa2lpn5p133pH6LVu2zJlR7k0zsw8//NCZGTBggDNz8MEHS/0WLVrkzKjrqPfee8+ZufDCC50Z5Zlmpl1X6jXTnXT05/Y5Zyj3pvp8VajPV2VN3q9fP2fmlFNOkfpt3LjRmVGe+UodM7NRo0Y5M+p78fLly50ZZf3w0UcfSf1mzJjhzCjvg2bauHxefwp1n8nX+xM/8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACJWEzmgaiUScmVgsJtVKS0tzZpKSkpyZ+Ph4qZ9Pffv2dWZGjRrlzLz//vtSv4KCAmfmmGOOcWZmzZol9UtPT3dmSkpKpFrV1dXOTFVVlTNTXl4u9aurq3NmKisrpVpNTU3OjHKsDj74YKlfQ0ODM6Pcg23JdQVxcd33+3g+x67MndnZ2VKtkSNHeulXX18v9VPu4Z49ezoztbW1Uj9l7OPHj5dqfe1rX3NmjjjiCGcmKytL6qccq4QE7RG/detWZ2bLli3OTEVFhdRPocyJZvpaoStQzkcQBB0wkvahrqN8nrOysjJnZtWqVc6MOiZl7iwtLXVmotGo1E+5HpS5wExbAyrz2KZNm6R+mZmZzsy6deukWv/+97+dGWWtr64BlWey+lw7++yzpVxXoHxun+sVtZayFvU5diWnznfKvd6jRw9v/VasWOHMjBgxwpm58MILpX6FhYXOzMsvvyzVUt71lHnl0EMPlfopaxbleJqZrV+/3plRnjM+7y/1Ha47rTuU+0C9Vzp6LuvoeSU3N1eqpeylKWutQw45ROr37rvveumnrkWUNdKiRYukWps3b3ZmlD0kJWOmvTcq+z5m2vWnzBndab74vO67UwQAAAAAAAAAwF6w8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEIlQQ3GxfnbI49EIs5MEARSraSkJGdGGXtycrLULyHBfciUjJlZZmamM5Obm+vMDBkyROqXmprqzEyePNmZGTx4sNSvsrLSmampqZFqVVVVeelXVFQk9auoqHBmGhoapFpr1qxxZq666ipnpk+fPlK/srIyKaeIj4/3VuurSpl/fM6vipSUFCnXo0cPZyYjI8OZ8fn5YrGYM6PMm2ZmAwcOdGbGjh0r1RoxYoSXfsrnM9Pmsu3bt0u1lPnuk08+cWa2bNki9VOeWQcccIBUq66uTsp1F8r6qDMo93A0GpVqNTc37+9wWjQ2Njoz2dnZzsywYcOkfsrzVbmH1Wer8vlU11xzjTNTXV3tzJx22mlSP+U8/+Y3v5FqJSYmOjNZWVnOjLJONDNbuXKlMzN37lyp1vDhw6VcV6DMP+rzXMmp852vNYRaRxmXOnYlp7yDqu8AyrvJsmXLnJmJEydK/c4//3xnZufOnVKtQw45xJlR1lHK3oCZWU5OjjOjrsnKy8udGeUZqcx1Zn73UpqamqRcV6Dcw+o5U46huqej1FKe++o6SlnXFBYWSrWUnunp6c6Mui+izAfKO0fPnj2lfsq9qa7JlHcOZZ0xcuRIqZ+yNlX30pR5UZkzfN5f6jPZ1xzFT3wDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEIlQQ1GIhFnJi5O20dXavkUi8WcmaSkJKmWkvN5HHr27OnMpKamSv2Sk5OdmdzcXGcmPj5e6ldXV+clY2ZWW1vrzFRUVDgzO3bs8NZv27ZtUq0xY8Y4M5dffrkzU1lZKfVLSHDf1s3NzVKtaDQq5boL9d7sij19jl2tlZKS4sykpaU5M1lZWVK/Pn36ODM1NTVSLYVyHwwcOFCq1a9fP2dGOZ7l5eVSPyWnzIlm2tyiHPeCggKp3/e//31nRrmuzPxeD+1NfXZ2NGWeV9YrTU1NUj9lTZaYmCjV6t27tzOTk5PjzJSVlUn9lDWLMr8qc4GZdhyUdaLq5ptvdmaWLFnird/atWul3LBhw7z0Ky0tlXITJ050ZubOnSvVqq6udmby8vKkWu1Nuc/Vd7iOnu+U+87n+2cQBFJOuYeV57n6rMvPz3dmVq9e7cz8/e9/l/pNmzbNmdm8ebNUS3lPVd7D1XfL9PR0Z0Z5pzIzq6+vd2Z87qUo1Otdfd52F+oxVHI+a/nUo0cPZ2bRokVSLWX9c9hhhzkzCxculPop6/vs7GxnRn23LCkpcWbU/SFlvazM54ceeqjUT9njU58NyjWqrM99XuvqPpOv9QQ/8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKgkdEbTIAicmfj4eKlWfX29l35xcdr3AJKTk71kzMyqq6ulnC8HHXSQM5OWlubM7Ny5U+pXVVXlzDQ2Nkq1ampqnJnS0lJnpqyszFs/dey33367M5OUlOTMNDU1Sf0ikYgzo95f3YlyD6v3uSIhQZs+ffX0OfZYLCbllOtSmTOysrKkftnZ2c6Mctzr6uq89cvPz5dqKcdBGZcyb3ZGLWXeT0lJkfrNmDHDmVGe7Wb6fdhddMZ97mvuVMeuPMsSExOlWg0NDVLORV23KZTnq3qvKPOKetxTU1OdGeU4LF++XOpXWVnpzOTm5kq1lGu5vLxcqqW47rrrnBn1/lLWZF2F8r6kfm4lp167yrii0agzo54LJefz/CvHYd26dVI/5VmtvOP861//kvopc5T6PFfmxYyMDGemublZ6qc8i9LT06VayvWnXMc+5wuln++e7c3nWH2ut5RaytpAuY7MtGe1su9jZrZ48WJn5oknnnBmPv74Y6nfDTfc4MyMHTvWmdm6davUT9lvU+copZZyjQ4fPlzqp1wP3fk9SH2Oqu8ELvzENwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAoZKgBmOxmDMTHx8v1YqLc++3KxkzsyAIpJyL8vnMzBITE52Z5ORkqVZzc7Mz09jY6Mzk5eVJ/UaNGuWl37p166R+ioqKCilXXl7uzOzYscOZqampkfoVFBQ4Mz/5yU+kWkcccYQzs3PnTmdGvScUCQnyrR8qPo+hz57K/KOO3de8ouaUfuqzITMz00s/Va9evZyZHj16SLXq6uqcmfr6ememsrJS6qfUqq6ulmop8+L27dudmXHjxkn9lGdRVVWVVKs7zWXKPRyJRKRavtY+ak8lo66jlHlFraWMq1+/fs7Mli1bpH5NTU3OjDLfqXNienq6lFOkpKR4yahrTiVXWFgo1VLW1SUlJc7MnDlzpH7Dhw93ZkpLS6VayntDd6KuRXzNKyplTlTnTZ/jUtYsylpk/PjxUr8VK1Y4M8pxSEtLk/r94x//cGauvPJKqZZynyvveuo1qqwz1GtGGbvPa1TJRaNRqVZnvBu1J5/3r/qsVnoq50N5BquKioqk3PLly52ZjRs3OjPKvWlmtnr1amfmwAMPdGYGDx4s9VPuc/VeUdaAu3btkmopfN6byjXqa8/CZz+fwjXTAQAAAAAAAAC+8tj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVBLkYIIc9VKroaFBqpWRkeHMRCIRZyY+Pl7q17NnT2empKREqhUEgTOjfL4+ffpI/bKyspyZ9evXOzPquYmLc39fZceOHVKtwsJCZ6ampsaZUT6fmdkZZ5zhzFx22WVSraqqKmfG5/2lUK49M+3e6U6Ua9K3WCzW4T1dlHvFzN+1m5SUJPVTcjk5Oc5MaWmp1C81NdWZqaurk2o1NjY6Mzt37nRmlLnOTDuH6tiV81xcXOzMfPvb35b6KedZvW86455uTz7nZvXYKMdaqaWuo9Q1hEK5hxXqcVfWgBUVFc6M+mxNTk52ZtTj7utZlJiY6C2XmZkp1dq4caOXWsrazsystrbWmVGPQ1dcA3wR5bpU7xWfn1u5xpU5Sr3vlM/oc33c3NzszPTr10+qlZeX58yUlZU5M/n5+VK/iRMnehmTmVlRUZEzU19f78won8/MbNeuXc6M+hxNSUlxZpT1srKWVIVtfWTmd+3jk6+eaWlpUk6ZEysrK6VaQ4cOdWYGDBjgzKjrsXHjxjkzyrveoEGDpH7RaNSZ+eijj6RayvyjrB+UMZnp6zuFr+eaOiaf96F6vFzCNyMCAAAAAAAAAL7S2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChkuCzWCQSkXKxWMyZaWpqkmr17t3bS7+EBO1QKLmkpCSpVnp6ujPT3NzszPTo0UPqV11d7cxs377dmcnIyJD6VVZWOjMFBQVSrcLCQmdmy5YtzszAgQOlfvPnz3dmGhoapFrx8fFSziUIAq+5jq7V3uLiOvb7eD77qfOPr1rq2JWc0i85OVnqp8wtynOmpqZG6qfMwWotxa5du5yZ8vJyqVZZWZkzU1VVJdUqKipyZpTzfPLJJ0v9lGPa0fdzGPm8z5WM+rxQrqXU1FRvtZT7PC8vT+qn3HcVFRXOjM81p3qeExMTnZm0tDRnJiUlReqnXA/qeVbmqHnz5jkzOTk5Uj9lHmaOgkK575S1QWNjo9QvMzPTmRk9erQzo7zDmWnv4crnMzMrKSlxZpS5QB278h6XlZUl1aqrq3NmlHd6dV5R9jbUfZmvKuX93Oc8r5wz5f410+aVXr16SbWUd7T33nvPmVHfAebOnevMvPzyy86MuhZR1nfq3lY0GnVmlHOorEtVPvcQFMoxUPl8T5HqeKkCAAAAAAAAAEAXwcY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChkqAGI5GIl4yZWVNTkzOTlpYm1crIyHBmysvLnZn4+HipX2NjozOzc+dOqZZyHFJTU73UMTNbuXKlMxMEgTNTU1Mj9SsrK3NmlHNjZrZ9+3ZnJhqNOjMPPvig1K9nz57OTF1dnVQLHSMuzt/38ZRaCQna9OlzXAplXD169JBqFRYW7u9wzMwsMzNTyilzWVVVlTOjzNNmZvX19d5q1dbWeskoYzIzKy4udmYqKiqkWuvXr3dmJk+e7MwcdNBBUj9l7B1933QE5TMpz2Azbb2lrmtisZgzo4xdqWOmjUudX5ubm50Z5R5W73NlbaqMXe2n1FKvmaSkJGdG+XzqvdnQ0ODMKGs7M7Nx48Y5MxdffLEzo8zBZmbJycnOjLLmDCP1XU+5z9VayrHuzs8M5Tio125KSoqXfsr7p5m2zlDnO6WWsgZU58TBgwc7M+o7r6/3VPW5rVDvLzXXXXT0+6CZv/Pm85wNGzZMqvXWW285M+np6c7MpZdeKvVT9oeKioqcGXVOVN4tlc9npu39KGstZZ5WqetlZY3u632gM2opuu8qAQAAAAAAAACAvWDjGwAAAAAAAAAQKmx8AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAgVNr4BAAAAAAAAAKHCxjcAAAAAAAAAIFTY+AYAAAAAAAAAhEqCGoxGo85MJBKRajU2NjozvXv3lmp98sknzsz27dudmZycHKlfXV2dM1NSUiLVUijHtLy8XKpVU1PjzMRiMWemqKhI6ldVVeXMrFu3Tqq1detWZ+a+++5zZiZMmCD1U8aelJQk1VLuHZ86ul93EhfXfb/X53PsaWlpUi4jI8NLv+bmZimnzK8VFRX7OZr/U1xc7MyUlZVJtZSxl5aWOjPq80OZ933Wuuqqq5wZ9Twrc6fyLGpLriuIj4/3Vquj5zJlLaKeC+U4NDQ0SLWU+66+vt6ZSUxMlPop164ybyrjNtOOexAEUi1FR5+bbdu2SbUuuugiZyYlJcWZqa2tlfopx0F95+lOlDlcnXsSEtyvmOoxVO5PpZ96nys5dT5XjpdSS51fk5OTnRnlWCl1zMw2b97szCjv4Wba9ZeamurM9OrVS+qnrIXXrl0r1crMzHRmlDlKfYdT7h31/vL5DGlvPudmn8dQuc+Vc6uei7y8PGdGfb4q+0PDhg1zZtR3xk2bNjkzyl6huhZR3nHUPR3l+lPmn9zcXKmfQr1GlbEr17HP9y6f7w2K7rsLBAAAAAAAAADAXrDxDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQiVBDcbFuffIGxsbpVrRaNSZSU9Pl2pt2rTJmdm6daszs23bNqlfLBZzZmpqaqRaQRA4M8pxr6qqkvopOeUclpSUSP22bNnizHzyySdSrRtvvNGZmTZtmjNTW1sr9UtMTJRyikgk4swo14KS+SpT7pXOqNUVJSUlSbmcnBxnprm52Zmprq6W+injysjIcGays7OlfvX19c5MYWGhVEuhzJ3l5eVSrbq6Omdm5cqVUq3p06d7yZSWlkr9wn5/fRFl/aAeG6WWSqnl85morAFVyj2srGvUOTEhwb1sTktLc2bUdaKSU/qZaWuIhoYGZ0Y9fzt27HBmevToIdU66aSTnBllfRcfHy/1U4RxHvvTn/7kzKhzgXJPpaSkSLWUnr4yZmapqanOjDIXmPm75vr16yflTj31VGdGuYeVudVM+3wbNmyQainHtFevXs7Mrl27pH7r1q1zZtR3XmUuq6iocGbUZ7tyrJT3TzO/z/f2prxz+HxfVp93PtdkisrKSmdm+fLlUq0BAwY4M01NTV4yZv7WZPn5+VI/5T5X12TKeVbenZV5zEzfW/VFnTN81erod57wrdoAAAAAAAAAAF9pbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqCXIwwR0tKSmRag0dOtSZaW5ulmpt27bNmamrq3NmampqpH5VVVVSTjFkyBAv/dauXSv1S01NlXIuO3bskHIfffSRM3PjjTdKtebMmePMNDU1OTOJiYlSP0UsFpNykUjESyYIAqmfT8q4uhP1nMXFub8nqGRUPmspn1E9DhkZGc5Mjx49nBl13lTm/YaGBmdGvc8bGxudGfXZoJxDpZbyvDLTnrfqcb/uuuucGeXcKOsEM/36+yrqjDnK1/lQ7icz7RpPTk6WainXpfIcU4+Vr+ew2q+6utqZSU9Pl2opc6eyjlLXBStWrHBmbrnlFqnWwIEDnZnS0lJnpqPvie5GuTd9rldUvtY16v3b0WvA+Ph4Z0a9JpV37D59+jgz6ju9Ql1HKfP+gAEDnBllLjDT1kjKnGimvRv//Oc/d2bUdZSSU9fCyvX34IMPSrXaWzQadWbUe0WZD5R+Ztp1oswZ9fX1Ur+NGzd6GZOZ2ciRI52Zd955x1s/hbL2UefztLQ0Z0adM5SeynolKSlJ6ldbW+vMqGsyX+tX9Z5Qcx2Jn/gGAAAAAAAAAIQKG98AAAAAAAAAgFBh4xsAAAAAAAAAECpsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBUEtRgdXW1MxMXp+2jDxo0yJnZtm2bVKu4uNiZKSkpcWZSU1OlfkVFRc5MRkaGVEs5Xps3b3ZmSktLpX5DhgxxZpTjuWzZMqnfzJkznZmLLrpIqhWLxZwZ9frz1U8ViUScmSAIvNRRc2otZVxdhc/zr9RSrxGlls9+PiUkuB8RSUlJzkxTU5OP4ZiZWc+ePZ2Z9PR0qVZ9fb0zU1FRIdVqbm52Zurq6pwZZUxmZp988okz8/Wvf12qNX36dGdGec4o1wu6J5/PFWU+aGhokGopzyglU1VVJfVT70+X+Ph4KdfY2OjM+BqTatOmTVJuypQpzsyFF14o1VLmH5/PUeWa8Vmrq0hJSfFWy+eaTKGsRXyufX2uyZRnp7oWeeedd5yZ008/3Vs/ZexpaWlSLeWaqaysdGaUedNMexap61d13emiPvuUz6jOPdFoVMp1BR09r6hzhkJ57qvPc+U6Oeqoo6RayrWk3MPqfafspSmZgoICqZ/y7qW+vyjzfm5urjOjrgGV60+9J5T7XPl8PvejfI5dwU98AwAAAAAAAABChY1vAAAAAAAAAECosPENAAAAAAAAAAgVNr4BAAAAAAAAAKHCxjcAAAAAAAAAIFTY+AYAAAAAAAAAhAob3wAAAAAAAACAUGHjGwAAAAAAAAAQKmx8AwAAAAAAAABCJUENlpWVOTMHHXSQVKu5udmZaWxs9FarvLzcmUlPT5f61dTUODNZWVlSreLiYmempKTEmUlI0E5jRUWFM7Ns2TJnpnfv3lK/efPmSTlflOMQBEEHjKR9ekYiESkXF+fv+1mdcbz2lfK5fR4bn7VisZi3Wsq4lHnTzN+4kpOTpVxOTo4zo4xdmVvNzKLRqDNTW1sr1VKOVV1dnTOjPGvNzOrr652Ziy66SKqlUJ8zCuUa9XlPdBVddf7xVUu5n8y0e7ihocFbT6WWOif6Olbq/eRrXjEzi4+Pd2aU+WfgwIFSv3vuuceZ6eh1jVpHOe5qraamJinXFaj3gUK53nxS3xsVSUlJ3mop15Iy9pSUFKnfhg0bnBllzujVq5fUT3kvTk1NlWrt2rXLmVHeixMTE6V+CvU9SDk/aWlpzox6DyrPEHUd5XN9150ozx91nvf1Dqo+L5T3KvXda/Pmzc6M8i60bds2qd+OHTucGWUtoozbTNv/Uu875fz079/fmeno66ozdMU9pK55pAAAAAAAAAAA2EdsfAMAAAAAAAAAQoWNbwAAAAAAAABAqLDxDQAAAAAAAAAIFTa+AQAAAAAAAAChwsY3AAAAAAAAACBU2PgGAAAAAAAAAIQKG98AAAAAAAAAgFCJBEEQdPYgAAAAAAAAAADwhZ/4BgAAAAAAAACEChvfAAAAAAAAAIBQYeMbAAAAAAAAABAqbHwDAAAAAAAAAEKFjW8AAAAAAAAAQKiw8Q0AAAAAAAAACBU2vgEAAAAAAAAAocLGNwAAAAAAAAAgVNj4BgAAAAAAAACEyv8HBnIu/Fse0YYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a few random test samples\n",
    "num_samples_to_show = 5\n",
    "indices = np.random.randint(0, X_test.shape[0], num_samples_to_show)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(1, num_samples_to_show, i+1)\n",
    "    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Pred: {y_pred[idx]}, True: {y_test[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c006823e-adb7-4d48-9956-da8c7dc99038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "\n",
    "class LogisticRegressionTuner:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        Initialize tuner with training and testing data\n",
    "        \n",
    "        Parameters:\n",
    "        - X_train: Training features\n",
    "        - X_test: Testing features\n",
    "        - y_train: Training labels\n",
    "        - y_test: Testing labels\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def cross_validate(self, learning_rate, num_iterations, n_splits=5):\n",
    "        \"\"\"\n",
    "        Perform cross-validation\n",
    "        \n",
    "        Parameters:\n",
    "        - learning_rate: Learning rate to test\n",
    "        - num_iterations: Number of iterations\n",
    "        - n_splits: Number of cross-validation splits\n",
    "        \n",
    "        Returns:\n",
    "        - Average cross-validation accuracy\n",
    "        \"\"\"\n",
    "        # Stratified K-Fold for maintaining class distribution\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        cv_scores = []\n",
    "        \n",
    "        for train_index, val_index in skf.split(self.X_train, self.y_train):\n",
    "            # Split data\n",
    "            X_train_cv = self.X_train[train_index]\n",
    "            y_train_cv = self.y_train[train_index]\n",
    "            X_val_cv = self.X_train[val_index]\n",
    "            y_val_cv = self.y_train[val_index]\n",
    "            \n",
    "            # Train model\n",
    "            clf = CustomLogisticRegression(\n",
    "                learning_rate=learning_rate, \n",
    "                num_iterations=num_iterations,\n",
    "                num_classes=len(np.unique(y_train_cv))\n",
    "            )\n",
    "            clf.fit(X_train_cv, y_train_cv)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            cv_accuracy = clf.accuracy(X_val_cv, y_val_cv)\n",
    "            cv_scores.append(cv_accuracy)\n",
    "        \n",
    "        return np.mean(cv_scores)\n",
    "    \n",
    "    def grid_search(self):\n",
    "        \"\"\"\n",
    "        Perform grid search for hyperparameters\n",
    "        \n",
    "        Returns:\n",
    "        - Best hyperparameters and their performance\n",
    "        \"\"\"\n",
    "        # Hyperparameter grid\n",
    "        learning_rates = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "        iterations_list = [500, 1000, 1500, 2000]\n",
    "        \n",
    "        # Store results\n",
    "        results = []\n",
    "        \n",
    "        # Grid search\n",
    "        for lr, iterations in product(learning_rates, iterations_list):\n",
    "            # Cross-validation\n",
    "            cv_accuracy = self.cross_validate(lr, iterations)\n",
    "            \n",
    "            # Final model evaluation on test set\n",
    "            clf = CustomLogisticRegression(\n",
    "                learning_rate=lr, \n",
    "                num_iterations=iterations,\n",
    "                num_classes=len(np.unique(self.y_train))\n",
    "            )\n",
    "            clf.fit(self.X_train, self.y_train)\n",
    "            test_accuracy = clf.accuracy(self.X_test, self.y_test)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'learning_rate': lr,\n",
    "                'iterations': iterations,\n",
    "                'cv_accuracy': cv_accuracy,\n",
    "                'test_accuracy': test_accuracy\n",
    "            })\n",
    "            \n",
    "            print(f\"LR: {lr}, Iterations: {iterations}\")\n",
    "            print(f\"CV Accuracy: {cv_accuracy * 100:.2f}%\")\n",
    "            print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\\n\")\n",
    "        \n",
    "        # Find best parameters\n",
    "        results_df = pd.DataFrame(results)\n",
    "        best_cv_row = results_df.loc[results_df['cv_accuracy'].idxmax()]\n",
    "        best_test_row = results_df.loc[results_df['test_accuracy'].idxmax()]\n",
    "        \n",
    "        print(\"Best by Cross-Validation:\")\n",
    "        print(best_cv_row)\n",
    "        print(\"\\nBest by Test Accuracy:\")\n",
    "        print(best_test_row)\n",
    "        \n",
    "        return results_df, best_cv_row, best_test_row\n",
    "    \n",
    "    def feature_importance(self):\n",
    "        \"\"\"\n",
    "        Analyze feature importance\n",
    "        \n",
    "        Returns:\n",
    "        - Feature importance scores\n",
    "        \"\"\"\n",
    "        # Train final model\n",
    "        clf = CustomLogisticRegression(\n",
    "            learning_rate=0.1, \n",
    "            num_iterations=1000,\n",
    "            num_classes=len(np.unique(self.y_train))\n",
    "        )\n",
    "        clf.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Compute feature importance based on absolute weight magnitudes\n",
    "        feature_importances = np.abs(clf.weights).mean(axis=1)\n",
    "        \n",
    "        # Sort features by importance\n",
    "        sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "        \n",
    "        # Visualize top 10 most important features\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Top 10 Most Important Features\")\n",
    "        plt.bar(range(10), feature_importances[sorted_indices[:10]])\n",
    "        plt.xlabel(\"Feature Index\")\n",
    "        plt.ylabel(\"Importance Score\")\n",
    "        plt.show()\n",
    "        \n",
    "        return feature_importances, sorted_indices\n",
    "\n",
    "# Additional utility function for dimensionality reduction\n",
    "def apply_pca(X_train, X_test, n_components=50):\n",
    "    \"\"\"\n",
    "    Apply PCA for dimensionality reduction\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - X_test: Testing features\n",
    "    - n_components: Number of components to keep\n",
    "    \n",
    "    Returns:\n",
    "    - Reduced X_train, X_test\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Explained variance\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "    \n",
    "    # Visualize explained variance\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'bo-')\n",
    "    plt.title('Cumulative Explained Variance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.show()\n",
    "    \n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "# Main execution function\n",
    "def hyperparameter_tuning(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Comprehensive hyperparameter tuning pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - X_test: Testing features\n",
    "    - y_train: Training labels\n",
    "    - y_test: Testing labels\n",
    "    \n",
    "    Returns:\n",
    "    - Tuning results\n",
    "    \"\"\"\n",
    "    # Tuning with original features\n",
    "    tuner = LogisticRegressionTuner(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Perform grid search\n",
    "    results_df, best_cv, best_test = tuner.grid_search()\n",
    "    \n",
    "    # Analyze feature importance\n",
    "    feature_importances, sorted_indices = tuner.feature_importance()\n",
    "    \n",
    "    # Optional: Apply PCA and retune\n",
    "    X_train_pca, X_test_pca = apply_pca(X_train, X_test)\n",
    "    \n",
    "    # Tuning with PCA-reduced features\n",
    "    pca_tuner = LogisticRegressionTuner(X_train_pca, X_test_pca, y_train, y_test)\n",
    "    pca_results_df, pca_best_cv, pca_best_test = pca_tuner.grid_search()\n",
    "    \n",
    "    return {\n",
    "        'original_results': results_df,\n",
    "        'best_cv': best_cv,\n",
    "        'best_test': best_test,\n",
    "        'pca_results': pca_results_df,\n",
    "        'pca_best_cv': pca_best_cv,\n",
    "        'pca_best_test': pca_best_test\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# results = hyperparameter_tuning(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580b6e4-fe05-4df3-81bc-95dbfe3bfd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.001, Iterations: 500\n",
      "CV Accuracy: 18.01%\n",
      "Test Accuracy: 11.73%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After preprocessing your data\n",
    "results = hyperparameter_tuning(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a28610-c3a4-44a3-9298-e2e7dc98cd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
