{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cede69c6-1488-4bf2-b7dc-b63aab36a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea8713d-7083-4389-8dc7-b8b61cba799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318016f0-7b17-4fcf-8750-2d8f9911cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_csv_path = './archive/sign_mnist_train.csv'\n",
    "train_data = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Load the testing dataset\n",
    "test_csv_path = './archive/sign_mnist_test.csv'\n",
    "test_data = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4710817-50f7-43be-8061-d9de85787548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (27455, 28, 28)\n",
      "Testing data shape: (7172, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "X_train = train_data.drop(\"label\", axis=1).values.reshape(-1, 28, 28) / 255.0  # Normalize pixel values\n",
    "y_train = train_data[\"label\"].values\n",
    "\n",
    "X_test = test_data.drop(\"label\", axis=1).values.reshape(-1, 28, 28) / 255.0\n",
    "y_test = test_data[\"label\"].values\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938cf610-2729-4271-a8f5-9198a4c597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomCNN:\n",
    "    def __init__(self, input_shape, num_classes, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Initialize the Custom CNN.\n",
    "        Parameters:\n",
    "        - input_shape: Shape of input data (e.g., (28, 28, 1) for grayscale images).\n",
    "        - num_classes: Number of output classes for classification.\n",
    "        - learning_rate: Learning rate for gradient descent.\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize filters for the convolution layer\n",
    "        self.filters = np.random.randn(8, 3, 3) * 0.1  # 8 filters of size 3x3\n",
    "\n",
    "        # Calculate the size of the flattened layer after convolution and pooling\n",
    "        conv_output_size = input_shape[0] - 2  # Subtract 2 because of 3x3 filters\n",
    "        pooled_output_size = conv_output_size // 2  # Divide by 2 because of 2x2 pooling\n",
    "        flattened_size = pooled_output_size * pooled_output_size * 8  # 8 filters\n",
    "        \n",
    "        # Initialize weights and biases for the fully connected layer\n",
    "        self.fc_weights = np.random.randn(flattened_size, num_classes) * 0.1\n",
    "        self.fc_biases = np.zeros((1, num_classes))\n",
    "\n",
    "\n",
    "    def relu(self, x):\n",
    "        \"\"\"Apply ReLU activation.\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        \"\"\"Derivative of ReLU.\"\"\"\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        \"\"\"Apply softmax activation.\"\"\"\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def convolve(self, image, filters):\n",
    "        \"\"\"Perform convolution.\"\"\"\n",
    "        h, w = image.shape\n",
    "        fh, fw = filters.shape[1], filters.shape[2]\n",
    "        output = np.zeros((h - fh + 1, w - fw + 1, filters.shape[0]))\n",
    "\n",
    "        for f in range(filters.shape[0]):  # Loop over filters\n",
    "            for i in range(h - fh + 1):\n",
    "                for j in range(w - fw + 1):\n",
    "                    region = image[i:i+fh, j:j+fw]\n",
    "                    output[i, j, f] = np.sum(region * filters[f])\n",
    "        return output\n",
    "\n",
    "    def pool(self, feature_map):\n",
    "        \"\"\"Apply max pooling.\"\"\"\n",
    "        h, w, c = feature_map.shape\n",
    "        pooled = np.zeros((h // 2, w // 2, c))\n",
    "\n",
    "        for k in range(c):  # Loop over channels\n",
    "            for i in range(0, h, 2):\n",
    "                for j in range(0, w, 2):\n",
    "                    pooled[i//2, j//2, k] = np.max(feature_map[i:i+2, j:j+2, k])\n",
    "        return pooled\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # Step 1: Convolution + ReLU\n",
    "        self.conv_output = self.relu(self.convolve(x, self.filters))\n",
    "\n",
    "        # Step 2: Pooling\n",
    "        self.pooled_output = self.pool(self.conv_output)\n",
    "\n",
    "        # Step 3: Flatten\n",
    "        self.flattened = self.pooled_output.flatten().reshape(1, -1)\n",
    "\n",
    "        # Step 4: Fully connected layer + Softmax\n",
    "        self.fc_output = np.dot(self.flattened, self.fc_weights) + self.fc_biases\n",
    "        self.probs = self.softmax(self.fc_output)\n",
    "\n",
    "        return self.probs\n",
    "\n",
    "    def backward(self, x, y_true):\n",
    "        \"\"\"Backward pass.\"\"\"\n",
    "        # Convert y_true to one-hot encoding\n",
    "        y_one_hot = np.zeros((1, self.num_classes))\n",
    "        y_one_hot[0, y_true] = 1\n",
    "\n",
    "        # Step 1: Gradient of loss w.r.t. fully connected layer\n",
    "        grad_fc_output = self.probs - y_one_hot\n",
    "        grad_fc_weights = np.dot(self.flattened.T, grad_fc_output)\n",
    "        grad_fc_biases = grad_fc_output\n",
    "\n",
    "        # Step 2: Backprop through flatten\n",
    "        grad_flattened = np.dot(grad_fc_output, self.fc_weights.T)\n",
    "        grad_pooled = grad_flattened.reshape(self.pooled_output.shape)\n",
    "\n",
    "        # Step 3: Backprop through pooling\n",
    "        grad_conv_output = np.zeros_like(self.conv_output)\n",
    "        for k in range(self.pooled_output.shape[2]):  # Loop over channels\n",
    "            for i in range(0, self.conv_output.shape[0], 2):\n",
    "                for j in range(0, self.conv_output.shape[1], 2):\n",
    "                    region = self.conv_output[i:i+2, j:j+2, k]\n",
    "                    max_value = np.max(region)\n",
    "                    grad_conv_output[i:i+2, j:j+2, k] += (region == max_value) * grad_pooled[i//2, j//2, k]\n",
    "\n",
    "        # Step 4: Backprop through ReLU\n",
    "        grad_conv_output *= self.relu_derivative(self.conv_output)\n",
    "\n",
    "        # Step 5: Backprop through convolution\n",
    "        grad_filters = np.zeros_like(self.filters)\n",
    "        for f in range(self.filters.shape[0]):\n",
    "            for i in range(x.shape[0] - self.filters.shape[1] + 1):\n",
    "                for j in range(x.shape[1] - self.filters.shape[2] + 1):\n",
    "                    region = x[i:i+self.filters.shape[1], j:j+self.filters.shape[2]]\n",
    "                    grad_filters[f] += region * grad_conv_output[i, j, f]\n",
    "\n",
    "        # Update parameters\n",
    "        self.filters -= self.learning_rate * grad_filters\n",
    "        self.fc_weights -= self.learning_rate * grad_fc_weights\n",
    "        self.fc_biases -= self.learning_rate * grad_fc_biases\n",
    "\n",
    "    def train(self, X, y, epochs=10):\n",
    "        \"\"\"Train the CNN.\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for i in range(len(X)):\n",
    "                # Forward pass\n",
    "                probs = self.forward(X[i])\n",
    "\n",
    "                # Compute loss (cross-entropy)\n",
    "                loss = -np.log(probs[0, y[i]])\n",
    "                total_loss += loss\n",
    "\n",
    "                # Backward pass\n",
    "                self.backward(X[i], y[i])\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(X):.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class for input data.\"\"\"\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            probs = self.forward(X[i])\n",
    "            predictions.append(np.argmax(probs))\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7123b5f-d383-4145-9520-b4ca526fc153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.2367\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the CNN\n",
    "cnn = CustomCNN(input_shape=(28, 28), num_classes=25, learning_rate=0.001)  # Set number of classes appropriately\n",
    "cnn.train(X_train[:1000], y_train[:1000], epochs=10)  # Train on a subset for faster results\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = cnn.predict(X_test[:200])\n",
    "accuracy = np.mean(y_pred == y_test[:200])\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d8692-6016-4172-97f2-e5965cbc94ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
